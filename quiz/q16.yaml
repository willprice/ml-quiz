images: []
difficulty: "3"
reference: "8.4"
problem_type: calculation
source: |
  Machine Learning: Distance Based Clustering : K-means algorithm
question:
  <p>
  Considering the following data points
  \begin{align}
  (2, 3, 2) (1, 4, 3) (0, 2, 3) (-1, 3, -1) (-2, 2, -2) (0, 0, -2)\\
  \end{align}
  compute the best k-means clusters taking into consideration only 2 dimensions and
  k=2 as the number of clusters.
  </p>
  <p>
  Following your chosen clustering choose the corresponding within-cluster scatter
  trace and between-cluster scatter trace.
  </p>

answer_type: multiple
answers:
  - correctness: "-"
    answer: "trace of S2 = 34.68 "
  - correctness: "+"
    answer: "trace of S1 is equal to trace of S2"
    explanation: "as computed in workings"
  - correctness: "+"
    answer: "trace of B = 33.96"
    explanation: "as computed in workings"
  - correctness: "-"
    answer: "trace of B = 30.12"

workings: |
  <p>
  Taking pairs of two of the 3 features and representin them on the coordinate axes
  will be the most efficient way to assess the chosen dimensions. While choosing
  the x and y dimensions will give us a cloud with high variance, the y and z will
  issolate a single point on the y axis that can either be an outlier or otherwise
  determines a high within-cluster scatter. Therefore, the x and z dimensions will
  be the one choosen as it both maximises the between-cluster scatter, but also
  minimises the within-cluster scatter.
  </p>
  <p>
  Even if visually it is easy to identify the clusters that will predict two different
  classes, an automatated distance-based cluster will have to follow the following
  KMeans algorithm:
  </p>

  <pre>
  <code class="python">
  KMeans(D, K):

  Input: data D; a natural number of clusters k;
  Output: K cluster means q{1},...,q{k}.

  randomly initialise K vectors q{1},...,q{k}
  repeat
    assign eaxh x form D to arg min Dist(x,q)
    for j = 1 to K do
      D{j} <- {x from D | x assigned to cluster j}
      q{j} = 1 / |D{j}| * sum of all x where x is from D{j}
    end
  untill no change in q{1},...,q{k};
  return q{1},...,q{k};
  </code>
  </pre>

  <p>
  However, making abstractions of the algorithm and taking into consideration
  the visual aids constructed we can conclude that the first 3 and the last 3
  will be grouped in the end in 2 different clusters.
  </p>

  <p>
  We will then proceed to partition the given data D into K subsets and let q{i}
  denote the mean of a cluster D{i}. Let S{j} be the scatter matrices of D{j} having
  the following relationship:
  </p>

  \begin{align}
  S &= \sum_{j \in k}\left[ S{j} + B \right]\\
  \end{align}
  where S{j} is called the within-clustre scatter matrix and B the between-cluster
  scatter matrix and describes the spread of the cluster centroids.

  <p>
  Therefore, we can next compute the cluster means as follows:
  </p>

  <ul>
    <li>q{1} = ( (2+ 1+ 0) / 3, (2+ 3+ 3) / 3) = ( 1, 2.6)</li>
    <li>q{2} = ( (-1+ -2+ 0) / 3, (-1+ -2+ -2) / 3) = ( -1, -1.6)</li>
  </ul>
  and the scatter matrixes:

  $$\mathbf{S{1}} =
  \begin{pmatrix}
    2-1 & 1-1 & 0-1\\
    2-2.6 & 3-2.6 & 3-2.6\\
  \end{pmatrix}
  \begin{pmatrix}
    2-1 & 2-2.6\\
    1-1 & 3-2.6\\
    0-1 & 3-2.6\\
  \end{pmatrix}
  =
  \begin{pmatrix}
    2 & -1    \\
    -1 & 0.68 \\
  \end{pmatrix}$$

  $$\mathbf{S{2}} =
  \begin{pmatrix}
    -1-(-1) & -2-(-1) & 0-(-1)\\
    -1-(-1.6) & -2-(-1.6) & -2-(-1.6)\\
  \end{pmatrix}
  \begin{pmatrix}
    -1-(-1) & -1-(-1.6)\\
    -2-(-1) & -2-(-1.6)\\
    0-(-1) & -2-(-1.6)\\
  \end{pmatrix}
  =
  \begin{pmatrix}
    2 & 0    \\
    0 & 0.68 \\
  \end{pmatrix}$$

  with traces:
  <ul>
    <li>Scat(D{1}) = 2.68</li>
    <li>Scat(D{2}) = 2.68</li>
  </ul>
  We next calculate the between-cluster sctter matrix as
  $$\mathbf{S{2}} =
  \begin{pmatrix}
    1 & 1 & 1 & -1 & -1 & -1\\
    2.6 & 2.6 & 2.6 & -1.6 & -1.6 & -1.6\\
  \end{pmatrix}
  \begin{pmatrix}
    1 & 2.6\\
    1 & 2.6\\
    1 & 2.6\\
    -1 & -1.6\\
    -1 & -1.6\\
    -1 & -1.6\\
  \end{pmatrix}
  =
  \begin{pmatrix}
    6 & 12.6    \\
    12.6 & 27.96 \\
  \end{pmatrix}$$
  with trace 33.96.



hint: |
  <p>
  Take pairs of two of the 3 features given and on the basis of your hints from
  xy/yz/xz axis representation compute their scatter matrix and choose the
  clustering that achieves minimum within-scatter trace and maximum between-scatter
  trace.
  </p>

comments: |
  Task of complexity 3 as it requires in addition to a deep understanding of the
  given concept that can reduce the complexity of the probleam also extensove
  computations to select the best design.
