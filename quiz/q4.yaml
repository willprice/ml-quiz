images:
  - url: img/nn-backprop-question-network.png
    caption: "Fig 1: Example neural network"
  - url: img/nn-backprop-question-circuit.png
    caption: |-
      Fig 2: Neural network from Fig 1 drawn as a circuit diagram,
      showing how to calculate intermediate values in forward propagation
  - url: img/nn-backprop-question-circuit-answer-abstract.png
    caption: |-
      Fig 3: Neural network from Fig 1 drawn as a circuit diagram,
      showing how to calculate intermediate values in back propagation
problem_type: training
difficulty: "5"
reference: "0"
source: "https://cs231n.github.io/optimization-1/"
question:
  - |
    <p>
    Neural networks (NNs) are a class versatile models used to great
    success in many different domains. A neural network is a directed
    graph of nodes and edges. Nodes (neurons), either represent inputs
    to the model or compute some function of their inputs. Edges
    represent connections between adjacent neurons, they have a weight
    associated with them. Most neurons compute the weighted sum of their
    inputs followed by a non-linear function application (such as the
    $\sigma$, or $\tanh$ function).
    </p>

    <p>
    NNs can be trained using a technique called
    <emph>backpropagation</emph>. The main idea behind backpropagation
    is the rate of change of the loss of an output neuron can be
    calculated with respect to the weights of the network through
    repeated application of the chain rule. The weights of the network
    can then be updated using gradient descent to reduce the loss.
    </p>


    <p>
    One might expect backpropagation to be very complicated as the
    number of neurons between an input and output neuron can be large,
    leading to a very complex gradient function, however the chain rule
    means we can decompose this into a series of simple calculations
    evaluating the derivative of the output of each neuron with respect
    to its input, these can then be combined through successive
    multiplications to calculate the change in loss with respect to a
    specific weight (see <a
    href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic
    differentiation</a>).
    </p>

    <p>
    A simple network is presented in Fig 1 composed of two
    input neurons and one output neuron. The output neuron computes the
    weighted sum of its inputs and applies the sigmoid function to
    produce its output.
    </p>

    <p>
    We will investigate how neural networks function by forward
    propagating (computing the output of the last layer of the network
    from a set of inputs), then backpropagating through the network to
    perform weight updates.
    </p>

    <p>
    Mathematical functions can be thought of as gates in a circuit that
    take inputs and produce an ouput, we will redraw the network in a
    circuit style breaking down the network into gates that we use to
    help perform back propagation.
    </p>

    <p>
    The network in Fig 1 has been redrawn as a circuit in Fig 2. Forward
    propagation is accomplished by applying the function specified in
    the node to its inputs, the calculations necessary to compute the
    output of each node are specified on the arrow between adjacent
    neurons. For the initial weights values $(w_1, w_2, w_3) = (2, -3,
    -3)$, and training example $(x_1, x_2) = (-1, -2)$, compute the
    top labelled values (those computed during forward propagation) in
    Fig 3.
    </p>

    <ul>
    <li>$a_1$
  - 1
  - |
    </li>
    <li>$a_2$
  - 2
  - |
    </li>
    <li>$b$
  - 3
  - |
    </li>
    <li>$c$
  - 4
  - |
    </li>
    <li>$\hat{y}$
  - 5
  - |
    </li>
    </ul>

  - |
    <p>
    Having got a feel for how forward propagation works, we'll now
    show you how to backpropagate. When training the network we need
    some way of quantifying the difference in predicted output to the
    expected output (ground truth). Loss functions are used to compute
    this difference, some common examples of loss functions include
    cross-entropy loss; and euclidean loss, the scaled sum of the
    squared error of each output neuron. Our example only has a single
    output neuron, so for the sake of simplicity we'll define loss as
    the difference between the output and the expected output.

    Our goal is to find
    $$\nabla_{w} L = \left[
      \frac{\partial L}{\partial w_1},
      \frac{\partial L}{\partial w_2},
      \ldots,
      \frac{\partial L}{\partial w_k}
    \right]$$

    Each term in the vector defines how the loss changes as you
    change a specific weight. $L$ represents a surface in a $k$
    dimensional space (if we hold $x$ constant), $\nabla_{w} L$ is the
    gradient at a specific point in that space defined by the current
    weights of the network. Since we want to reduce the loss and make
    our network more accurate, we can use gradient descent to traverse
    the surface to a hollow, this is not necessarily a global minima,
    but in practice gradient descent works well and produces networks
    that successfully function in their task.
    </p>

    <p>
    Let's look at a component of $\nabla_w L$, and figure out how to
    derive it.
    $$\frac{\partial L}{\partial w_1}$$
    Recall this represents how the loss of the network changes as we
    change weight $w_1$. We can decompose this into the product of
    multiple partial derivatives, each partial derivative representing
    how the output of a neuron changes with respect to its input, until
    we reach the beginning of the network.
    </p>

    <p>
    The input to each neuron has been labelled with a variable name on
    Fig 2, the partial derivatives of the loss with respect to the weights are:
    $$\frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial b}
                                        \frac{\partial b}{\partial a_1}
                                        \frac{\partial a_1}{\partial w_1}$$
    $$\frac{\partial L}{\partial w_2} = \frac{\partial L}{\partial b}
                                        \frac{\partial b}{\partial a_2}
                                        \frac{\partial a_2}{\partial w_2}$$
    If we compute the analytical derivative of the output of each
    neuron with respect to its input, we can construct an algorithm to
    work backwards through the network to compute the gradient of the
    loss with respect to the weights.
    </p>

    <p>
    Compute the following derivatives:
      $$\frac{d}{dx}(x + y)$$
      $$\frac{d}{dx}(x \cdot y)$$
      $$\frac{d}{dx}(\sigma(y))$$
    Where
      $$\sigma(x) = \frac{1}{1 + e^x}$$
    </p>

    <p>
    Finally we can backpropagate and find out how changing the weights
    affects the loss, starting from the output gate we can trace our
    way back to an input weight by accumulating the derivative product
    (i.e. incrementally build up the full partial derivative via the
    chain rule). As we traverse a gate, we compute the partial
    derivative and multiply the accumulator by the derivative until
    reaching the input weight.
    </p>

    <p>
    Following the above process, backpropagate the circuit in Fig 3.
    </p>

    What are the following partial derivatives?

    <ul>
    <li>$\frac{\partial L}{\partial w_1}$ =
  - 6
  - |
    </li>
    <li>$\frac{\partial L}{\partial w_2}$ =
  - 7
  - |
    </li>
    <li>$\frac{\partial L}{\partial w_3}$ =
  - 8
  - |
    </li>
    </ul>


answer_type: blank_answer
answers:
  - correctness: 1
    answer: "-2"
    explanation: See the workings for derivation
  - correctness: 2
    answer: "6"
    explanation: See the workings for derivation
  - correctness: 3
    answer: "4"
    explanation: See the workings for derivation
  - correctness: 4
    answer: "1"
    explanation: See the workings for derivation
  - correctness: 5
    answer: "0.73"
    explanation: See the workings for derivation
  - correctness: 6
    answer: "-0.20"
    explanation: See the workings for derivation
  - correctness: 7
    answer: "-0.40"
    explanation: See the workings for derivation
  - correctness: 8
    answer: "0.20"
    explanation: See the workings for derivation
workings: |-
  <p>
  Solving for the intermediate values in forward propagation:
  $$\begin{align}
    a_1 &= x_1w_1 = -1 \cdot 2 = -2 \\
    a_2 &= x_2w_2 = -2 \cdot -3 = 6 \\
    b &= x_1w_1 + x_2w_2 = -2 + 6 = 4 \\
    c &= (x_1w_1 + x_2w_2) + w_3= 4 + (-3) = 1 \\
    \hat{y} &= \sigma(x_1w_1 + x_2w_2 + w_3)= \sigma(1) = \frac{1}{1 + e^{-1}} = 0.731
  \end{align}$$
  </p>

  <p>
  Derivation of $\frac{d}{dx}(x + y)$
  $$\begin{align}
      \frac{d}{dx}(x + y) &= 1
    \end{align}$$
  </p>

  <p>
  Derivation of $\frac{d}{dx}(xy)$
  $$\begin{align}
      \frac{d}{dx}(xy) &= y
    \end{align}$$
  </p>

  <p>
  Derivation of $\frac{d}{dx}\sigma(x)$
  $$\begin{align}
      \frac{d}{dx}\sigma(x) &= \frac{d}{dx}\left(\frac{1}{1 + e^{-x}}\right) \\
                            &= \frac{d}{du}\left(\frac{1}{u}\right) \cdot \frac{d}{dx}\left(1 + e^{-x}\right) \\
                            &= -(1 + e^{-x})^{-2} \cdot e^{-x} \cdot (-1) \\
                            &= (1 + e^{-x})^{-2} \cdot e^{-x} \\
                            &= \frac{1}{(1 + e^{-x})^2} \cdot e^{-x} \\
                            &= \frac{e^{-x}}{1 + e^{-x}} \cdot \frac{1}{1 + e^{-x}} \\
                            &= \frac{1 + e^{-x} - 1}{1 + e^{-x}} \cdot \frac{1}{1 + e^{-x}} \\
                            &= \left(\frac{1 + e^{-x}}{1 + e^{-x}} - \frac{1}{1 + e^{-x}}\right) \cdot \frac{1}{1 + e^{-x}} \\
                            &= \left(1 - \frac{1}{1 + e^{-x}}\right) \cdot \frac{1}{1 + e^{-x}} \\
                            &= \sigma(x) \left( 1 - \sigma(x) \right)
    \end{align}$$
    </p>

    <p>
    Solving for intermediate values in back propagation using the
    results above yields the following analytical solutions

    $$\frac{\partial L}{\partial c} = \frac{\partial \sigma(c)}{\partial c} = \sigma(c)(1 - \sigma(c))$$
    $$\frac{\partial c}{\partial b} = \frac{\partial (b + w_3)}{\partial b} = 1$$
    $$\frac{\partial c}{\partial w_3} = \frac{\partial (b + w_3)}{\partial w_3} = 1$$
    $$\frac{\partial b}{\partial a_1} = \frac{\partial (a_1 + a_2)}{\partial a_1} = 1$$
    $$\frac{\partial b}{\partial a_2} = \frac{\partial (a_1 + a_2)}{\partial a_2} = 1$$
    $$\frac{\partial a_1}{\partial w_1} = \frac{\partial (x_1w_1)}{\partial w_1} = x_1$$
    $$\frac{\partial a_2}{\partial w_2} = \frac{\partial (x_2w_2)}{\partial w_2} = x_2$$

    Substituting the values calculated in forward propagation:

    $$\frac{\partial L}{\partial c} = 0.731(1 - 0.731) = 0.200$$
    $$\frac{\partial c}{\partial b} = 1$$
    $$\frac{\partial c}{\partial w_3} = 1$$
    $$\frac{\partial b}{\partial a_1} = 1$$
    $$\frac{\partial b}{\partial a_2} = 1$$
    $$\frac{\partial a_1}{\partial w_1} = x_1 = -1$$
    $$\frac{\partial a_2}{\partial w_2} = x_2 = -2$$

    Using the chain rule we can find the desired partial derivatives:
    $$\frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial c}
                                        \frac{\partial c}{\partial b}
                                        \frac{\partial b}{\partial a_1}
                                        \frac{\partial a_1}{\partial w_1}
                                      = 0.200 \cdot 1 \cdot 1 \cdot -1 = -0.20
    $$
    $$\frac{\partial L}{\partial w_2} = \frac{\partial L}{\partial c}
                                        \frac{\partial c}{\partial b}
                                        \frac{\partial b}{\partial a_2}
                                        \frac{\partial a_2}{\partial w_2}
                                      = 0.200 \cdot 1 \cdot 1 \cdot -2 = -0.40
    $$
    $$\frac{\partial L}{\partial w_3} = \frac{\partial L}{\partial c}
                                        \frac{\partial c}{\partial w_3}
                                      = 0.200 \cdot 1 = 0.20
    $$
    </p>
hint: |
  Blah

comments: |
  Tests the student's knowledge of neural networks and the circuit
  interpretation of backpropagation.

  <br />
  Complexity 5 because it is out the scope of the book and requires
  both calculation, and insight to derive the derivative of
  $\sigma(x)$ in terms of itself
